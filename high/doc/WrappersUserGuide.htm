<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0//EN">
<html><head>
<link rel="STYLESHEET" href="style.css" charset="ISO-8859-1" type="text/css">
<title>PNL Wrappers: User Guide</title>
</head><body>

<center><table cellspacing=0 cellpadding=5 width="90%" bgcolor="#6a9bed" nosave >
<tr nosave>
<td nosave>
<center><i><font color="#000000"><font size=+4>
PNL Wrappers: User Guide
</font></font></i></center>
</td>
</tr>
</table></center>
<HR>

<P>
  <h4>
<UL>
  <LI><A href="#Intro">Intro</A> 
  <LI><A href="#DiscreteNet">Bayesian networks with discrete nodes</A> 
  <UL>  
      <LI><A href="#CreateNetDiscr">Creating the net</A> 
      <UL>
          <LI><A href="#AddNodesDiscr">Adding nodes</A> 
          <LI><A href="#AddEdgesDiscr">Adding edges</A> 
      </UL>
      <LI><A href="#SpecProbDiscr">Specifying the probabilities</A> 
      <LI><A href="#AddObservDiscr">Adding observations</A> 
      <LI><A href="#LearnDiscr">Learning the network</A> 
      <LI><A href="#MPEandJPDDiscr">Getting MPE and JPD</A> 
      <LI><A href="#HintsDiscr">Hints</A> 
      <UL>
          <LI><A href="#Operation1Discr">“^” operation</A> 
          <LI><A href="#Operation2Discr">[ ] operation</A> 
          <LI><A href="#StrAndFltMethodsDiscr">String and FltValue methods</A> 
      </UL>
  </UL>
  <LI><A href="#Gaussian">Bayesian networks with continuous nodes</A> 
  <UL>  
      <LI><A href="#CreateNetGau">Creating the net</A> 
      <UL>
          <LI><A href="#AddNodesGau">Adding nodes</A> 
          <LI><A href="#AddEdgesGau">Adding edges</A> 
      </UL>
      <LI><A href="#SpecProbGau">Specifying the probabilities</A> 
      <LI><A href="#AddObservGau">Adding observations</A> 
      <LI><A href="#LearnGau">Learning the network</A> 
      <LI><A href="#MPEandJPDGau">Getting MPE and JPD</A> 
      <LI><A href="#HintsGau">Hints</A> 
  </UL>
  </UL>
  </h4>

<P></P>
<hr>
<h1><a name="Intro">Intro</a></h1>

<hr>
<P>
This manual describes usage of PNL with the help of wrappers.
It is BayesNet  class, that is used for working with Bayesian networks in wrappers. 
It is main class, all the operations are made by it. This class allows user 
<UL>
    <LI>to create new Bayesian network,</LI>
    <LI>to specify probability distributions on the net nodes,</LI>
    <LI>to assign observations (evidences),</LI>
    <LI>to carry out learning process,</LI>
    <LI>to get joint probability distribution (JPD) and maximum probability explanation (MPE) for network nodes,</LI>
    <LI>to save Bayesian network and observations (evidences) as files and to load them from files,
    <br>etc.</LI>
</UL>
With the help of BayesNet class methods user specifies parameters of the network, evidences and other net 
characteristics and demands desired results. Required algorithms are called automatically. Learning 
and inference processes can be carried out with the help of different PNL algorithms. If it is not 
convenient for user to use default algorithm, he can specify definite algorithm that he want to use 
to solve his task.
<p>
<hr>

<h1><a name="DiscreteNet">Bayesian networks with discrete nodes</a></h1>
We are going to analyze Bayesian network functioning by the well-known example of “water-sprinkler”. 
<br>The graph structure of the model and the parameters are all shown in Figure 1:
</P>
<hr>
<h4><a name="figWaterSprinkler">Figure1. Water-sprinkler model</a></h4>
<img align=center src="WSModel.gif">
<p>
All nodes are discrete and can take on two values: true or false.
</p>
<hr>

<h2><a name="CreateNetDiscr">Creating the net</a></h2>
<p>
The first step of operating the Bayesian network is its creation. No other actions can be carried out, 
while there is no network.
<br>
To start network building we must create BayesNet class object: 
<p>
<pre>BayesNet net;</pre>
</p>
Now network is empty. We have to add nodes and edges.
</p>
<hr>

<h3><a name="AddNodesDiscr">Adding nodes</a></h3>
<p>
Method AddNode is used to add new node to the network:
<p>
<pre>
net.AddNode("discrete^Cloudy", "true false"); 
net.AddNode("discrete^Sprinkler", "true false");
net.AddNode("discrete^Rain", "true false");
net.AddNode("discrete^WetGrass", "true false");
</pre>
</p>

The first argument of this method is type and name of the new node, second argument is the corresponding 
variate values list, and values are separated by the space.
<br>
In our example all the nodes are discrete and can take on the same values, so all the nodes can be 
added by the one call of AddNode method:
<p>
<pre>
net.AddNode(discrete^"Cloudy Sprinkler Rain WetGrass", "true false");
</pre>
</p>
<hr>

<h3><a name="AddEdgesDiscr">Adding edges</a></h3>
<p>
AddArc method is used to add a new arc to the network:
<p>
<pre>
net.AddArc("Cloudy", "Sprinkler");
net.AddArc("Cloudy", "Rain");
net.AddArc("Sprinkler", "WetGrass");
net.AddArc("Rain", "WetGrass");
</pre>
</p>
We can indicate several nodes as the beginning and end of the arc. In this case every node from the beginning 
list will be connected with every node from the end list. In our example two calls of AddArc method are enough:
<p>
<pre>
net.AddArc("Cloudy", "Sprinkler Rain");
net.AddArc("Sprinkler Rain", "WetGrass");
</pre>
</p>
<hr>

<h2><a name="SpecProbDiscr">Specifying the probabilities</a></h2>
<p>
Now we can specify the probabilities on the network nodes. Default probability distribution is uniform. If we know probability distributions on some of the network nodes, we can specify them with the SetPTabular method for the discrete nodes.
<br>
In our example we are going to specify probability distributions on the Cloudy and Sprinkler nodes.  We will leave the distributions on the other nodes uniform.
<br>
Probability distribution on the Cloudy node is unconditional:
<p>
<pre>
net.SetPTabular("Cloudy^true", "0.6");
net.SetPTabular("Cloudy^false", "0.4"); 
</pre>
</p>
The first argument of this method is the state of the variable; we define the probability for the node to take on this state. The second argument is the value of probability. It is possible to define the list of states and list of values:
<p>
<pre>
net.SetPTabular("Cloudy^true Cloudy^false", "0.6 0.4");
</pre>
</p>
Probability distribution on the Sprinkler node is conditional:
<p>
<pre>
net.SetPTabular("Sprinkler^true", "0.1", "Cloudy^true");
net.SetPTabular("Sprinkler^false", "0.9", "Cloudy^true");
net.SetPTabular("Sprinkler^true", "0.5", "Cloudy^false");
net.SetPTabular("Sprinkler^false", "0.5", "Cloudy^false");
</pre>
</p>
For the conditional distribution one new argument was added. This argument specifies the parents state configuration, the probability value is defined for the indicated state and indicated parent’s configuration. The probabilities for the same parents configuration can be defined by the one call of SetPTabular method:
<p>
<pre>
net.SetPTabular("Sprinkler^true Sprinkler^false", "0.1 0.9", "Cloudy^true");
net.SetPTabular("Sprinkler^true Sprinkler^false", "0.5 0.5", "Cloudy^false");
</pre>
</p>
To get the probability distribution of the node we must call of GetPTabular method:
<p>
<pre>
TokArr PCloudy = net.GetPTabular("Cloudy");
</pre>
</p>
Now it is possible to represent this distribution as string or as float numbers: 
<p>
<pre>
String PCloudyStr = PCloudy.String();
float PCloudyTrueF = PCloudy[0].FltValue(0).fl;
float PCloudyFalseF = PCloudy[1].FltValue().fl;
</pre>
</p>
The following values are now stored in the variables:
<p>
<pre>
PCloudyStr		"Cloudy^true^0.6 Cloudy^false^0.4"
PCloudyTrueF		0.6
PCloudyFalseF		0.4
</pre>
</p>
For the conditional distribution it is possible to get probabilities for the indicated parents state configuration (or for the definite states of some parents):
<p>
<pre>
TokArr PSprinkler = net.GetPTabular("Sprinkler", "Cloudy^true");
String PSprinklerStr = PSprinkler.String();
float PSprinklerTrue = PSprinkler[0].FltValue();
float PSprinklerFalse = PSprinkler[1].FltValue();
</pre>
</p>
The values of the variables:
<p>
<pre>
PSprinklerStr		"Sprinkler^true^Cloudy^true^0.1 Sprinkler^false^Cloudy^true^0.9"
PSprinklerTrue		0.1
PsprinklerFalse		0.9
</pre>
</p>
With the help of  GetPTabular method user can also get the probability of some state of the variate:
<p>
<pre>
TokArr PCloudyFalse = net.GetPTabular("Cloudy^false");
</pre>
</p>
Now it is possible to represent this distribution  as string or as float number:
<p>
<pre>
String PCloudyFalseStr = PCloudyFalse.String();
float PCloudyFalseF = PCloudyFalse[0].FloatValue();
</pre>
</p>
The values of the variables:
<p>
<pre>
PCloudyFalseStr		"Cloudy^false^0.4"
PCloudyFalseF		0.4
</pre>
</p>
<p>
We can carry out Learning, i.e. to find out distributions on the network nodes with the help of one observation or some set of observations. We have to specify observations first.
</p>
<hr>

<h2><a name="AddObservDiscr">Adding observations</a></h2>
<p>
Here we will describe the way of working with evidences in wrappers. BayesNet class allows user to work with current evidence and with the buffer of evidences.
<br>
Default current evidence is empty. User can edit it with the EditEvidence method:
<p>
<pre>
net.EditEvidence("Cloudy^false WetGrass^false");
net.EditEvidence("Sprinkler^true Cloudy^true");
</pre>
</p>
After these calls there is three observed nodes in the current evidence, they are Cloudy, Sprinkler (both are true) and WetGrass, which is false.
<br>
After editing user can copy current evidence to the evidence buffer with the help of  CurEvidToBuf method:
<p>
<pre>
net.CurEvidToBuf();
</pre>
</p>
It is possible to clear the current evidence with ClearEvid method:
<p>
<pre>
net.ClearEvid();
</pre>
</p>
You can also put evidence-to-evidence buffer without editing. Call AddEvidToBuf method:
<p>
<pre>
net.AddEvidToBuf("Rain^true WetGrass^true");
</pre>
</p>
At the moment we have empty current evidence. Evidence buffer contains 2 evidences. In the first evidence, which was copied from the current evidence, there are three observed nodes: Cloudy, Sprinkler (both are true) and WetGrass (false). In second evidence there are two observed nodes, Rain and WetGrass, both are true.
<br>
The main operations with evidence buffer are:
<UL>
    <LI>total clearance of the buffer with the help of  ClearEvidBuf method,</LI>
    <LI>saving the buffer to file (SaveEvidBuffer) and loading buffer from file (LoadEvidBuffer). We support the csv file format,</LI>
    <LI>filling the evidence buffer with random values of observations with the help of GenerateEvidences method.</LI>
</UL>
Current evidence is used to get JPD and MPE, evidence buffer is used for learning.
</p>
<hr>

<h2><a name="LearnDiscr">Learning the network</a></h2>
<p>
To carry out learning process evidences from evidence buffer are used. 
<br>
It is possible to specify probability distributions on the net nodes with the help of learning. This setting of probabilities is named parameters learning. We can find out not only probability distributions, but also the net structure, i.e. structure of net edges. This process is named structural learning.
<br>
If we are going to specify probability distributions for network nodes, then we will call LearnParameters method after filling the evidence buffer to learn the network:
<p>
<pre>
net.LearnParameters();
</pre>
</p>
As a result, the probability distributions on the nodes have been changed. To get new distributions GetPTabular method is used:
<p>
<pre>
TokArr PCloudy = net.GetPTabular("Cloudy");
TokArr PSprinkler = net.GetPTabular("Sprinkler");
TokArr PRain = net.GetPTabular("Sprinkler");
TokArr PWetGrass = net.GetPTabular("WetGrass");
</pre>
</p>
Now distributions are presented as TokArr type objects. They can be converted into strings or float numbers, as it was shown earlier. They also can be used as arguments for other methods. 
<br>
Default learning algorithm is Expectation Maximization algorithm. You also can carry out learning using Bayesian method. You have to set “Learning” property to “bayes” by SetProperty method:
<p>
<pre>
net.SetProperty("Learning", "bayes");
net.LearnParameters();
</pre>
</p>
To run EM learning algorithm set the “Learning” property to “em”:
<p>
<pre>
net.SetProperty("Learning", "em");
net.LearnParameters();
</pre>
</p>
If we are going to find not only distributions, but also the network structure, we will call LearnStructure method:
<p>
<pre>
net.LearnStructure();
</pre>
</p>
In this case probability distributions and network structure have been changed. New distributions can be taken with the help of GetPTabular method. We can investigate new network structure using following methods: GetNeighbors, GetParents and GetChildren. For example:
<p>
<pre>
TokArr SprinklerParents = net.GetParents("Sprinkler");
TokArr SprinklerChildren = net.GetChildren("Sprinkler");
</pre>
</p>
SprinklerParents and SprinklerChildren are the lists of Sprinkler node parents and children. They can be used as arguments for other methods, or can be converted to strings objects for displaying:
<p>
<pre>
String SprinklerParentsStr = SprinklerParents.String();
String SprinklerChildrenStr = SprinklerChildren.String();
</pre>
</p>
Another way of getting the learning results is saving the final net to file (SaveNet method).
<br>
We must mention that  LearnParameters and LearnStructure methods can get two arguments: array of evidences and number of evidences in this array:
<p>
<pre>
TokArr evidences[] = {"Sprinkler^true WetGrass^false", "Cloudy^true WetGrass^false"};
net.LearnParameters(evidences, 2);
</pre>
</p>
In this case two new evidences will be added to evidence buffer and then learning process will be carried out using all evidences from the buffer.
</p>
<hr>

<h2><a name="MPEandJPDDiscr">Getting MPE and JPD</a></h2>
<p>
If Bayesian network and probability distributions have been already defined, we can get Joint Probability Distribution (JPD) and Maximum Probability Explanation (MPE).
<br>
For calculating JPD and MPE current evidence is used. You can edit this evidence with the help of  EditEvidence method (look through “Adding observations” section).
<br>
You can use GetJPD method to get the marginal probability distribution of the node:  
<p>
<pre>
TokArr WetGrassMarg = net.GetJPD("WetGrass");
</pre>
</p>
It is possible to get joint distribution for the nodes from one family (family is the set, which consists of node and node parents):
<p>
<pre>
TokArr WetGrassAndSprinklerMarg = net.GetJPD("WetGrass Sprinkler");
</pre>
</p>
You can use GetMPE method to get Maximum Probability Explanation for one node or for some set of nodes from one family:
<p>
<pre>
TokArr WetGrassMPE = net.GetMPE("WetGrass");
TokArr WetGrassAndSprinklerMPE = net.GetMPE("WetGrass Sprinkler");
</pre>
</p>
To calculate JPD and MPE inference algorithms are used. There are four inference algorithms: Pearl (or Loopy Belief Propagation), Junction Tree, Gibbs Sampling and full summation, which is called PNL Naive inference. We must mention, that Junction Tree and Naive Inference are exact, Pearl Inference and Gibbs Sampling are approximate algorithms (see PNL documentation for the full information).
<br>
Default inference algorithm, which is used to calculate MPE and JPD, is Pearl Inference. You can use other algorithms by setting “Inference” property with SetProperty method. You must define the desired algrithm by its string name: “pearl”, “jtree”, “gibbs”, or “naive”. For example:
<p>
<pre>
net.SetProperty("Inference", "jtree");
TokArr WetGrassMPE = net.GetMPE("WetGrass");
net.SetProperty("Inference", "gibbs");
TokArr WetGrassMPE = net.GetMPE("WetGrass Sprinkler");
</pre>
</p>
<hr>

<h2><a name="HintsDiscr">Hints</a></h2>
<p>
Now we are going to discuss some additional possibilities of parameters definition with the help of TokArr class.
</p>
<hr>

<h3><a name="Operation1Discr">“^” operation</a></h3>
<p>
If we use operation “^”, we can make parameters definition shorter. 
<br>
The following three pieces of code are equal:
</p>
<table width="100%">
<tr>
<td><pre>(1)</pre></td>
<td>
<pre>
net.AddNode("discrete^Cloudy discrete^Sprinkler discrete^Rain discrete^WetGrass", "true false");
</pre>
</td>
</tr>
<tr>
<td><pre>(2)</pre></td>
<td>
<pre>
TokArr nodeType = "discrete";
net.AddNode(nodeType^"Cloudy Sprinkler Rain WetGrass", "true false");
</pre>
</td>
</tr>
<tr>
<td><pre>(3)</pre></td>
<td>
<pre>
net.AddNode(discrete^"Cloudy Sprinkler Rain WetGrass", "true false");
</pre>
</td>
</tr>
</table>
<p>
When we compare pieces (1) and (2), we can see that “^” operation carries out Cartesian product of two TokArr objects.
<br>
It is possible to use (3) variant, because there is global variables of  TokArr type for all types of nodes. These variables specify the node types: 
<p>
<pre>
extern TokArr discrete;
extern TokArr continuous;
</pre>
</p>
</p>
<hr>

<h3><a name="Operation2Discr">[ ] operation</a></h3>
<p>
If  TokArr class object specifies some set of network nodes, then we can get every node with the help of  [] operation. Result of this operation is a Tok class object, which specifies only one node (TokArr = array of Tok):
<p>
<pre>
TokArr nodes = "Cloudy Sprinkler Rain WetGrass";
Tok node0 = nodes[0];
Tok node1 = nodes[1];
Tok node2 = nodes[2];
Tok node3 = nodes[3];
</pre>
</p>
Tok class object can be converted into string. For example, the result of conversion of node0 into string ( node0.String() )  is “Cloudy”.
</p>
<hr>

<h3><a name="StrAndFltMethodsDiscr">String and FltValue methods</a></h3>
<p>
To convert TokArr and Tok class objects into strings String method is used:
<p>
<pre>
TokArr distribution = "Cloudy^true^0.6 Cloudy^false^0.4";
Tok probabilityTrue = distribution[0];
Tok probabilityFalse = distribution[1];
</p><p>
String distributionStr = distribution.String();
String probabilityTrueStr = probabilityTrue.String();
String probabilityFalseStr = probabilityFalse.String();
</pre>
</p>
If Tok class variable contains the value of probability, then it is possible to get this value as a float number with the help of FltValue method:
<p>
<pre>
float probabTrueF = probabilityTrue.FltValue();
float probabFalseF = probabilityFalse.FltValue();
</pre>
</p>
probabTrueF and probabFalseF variables will contain 0.6 and 0.4 values correspondingly.
</p>
<hr>



<P></P>
<h1><a name="Gaussian">Bayesian networks with continuous nodes</a></h1>

<P>
We will show the operations with Bayesian network, which consists of continuous nodes, by the example of Satnam Alag’s PhD thesis, USB ME dept 1996 p. 48.
<br>The graph structure of the model and the parameters are all shown in Figure 2:
</p>
<hr>
<h4><a name="figModel">Figure 2. Simple model with continuous nodes</a></h4>
<img align=center src="GauModel.gif">
<p>All nodes are continuous and have only one dimension.
</p>
<hr>

<h2><a name="CreateNetGau">Creating the net</a></h2>
<p>
The first step of operating the Bayesian network is its creation. No other actions can be carried out, 
while there is no network.
<br>
To start network building we must create BayesNet class object: 
<pre>BayesNet net;</pre>
Now network is empty. We have to add nodes and edges.
</p>
<hr>

<h3><a name="AddNodesGau">Adding nodes</a></h3>
<p>
Method AddNode is used to add new node to the network:
<p>
<pre>
net.AddNode("continuous^x0", "dim1"); 
net.AddNode("continuous^x1", "dim1"); 
net.AddNode("continuous^x2", "dim1"); 
net.AddNode("continuous^x3", "dim1"); 
net.AddNode("continuous^x4", "dim1");
</pre>
</p>
The first argument of this method is type and name of the new node.  The second argument is the name of dimension. In our example all nodes have only one dimension, and that is why the second argument is always the same – the name of single dimension. The name of dimension is essential only for user, it can be chosen at will.
</p>
<hr>

<h3><a name="AddEdgesGau">Adding edges</a></h3>
<p>
AddArc method is used to add a new arc to the network:
<p>
<pre>
net.AddArc("x0", "x2");
net.AddArc("x1", "x2");
net.AddArc("x2", "x3");
net.AddArc("x2", "x4");
</pre>
</p>
Adding new edges is similar to the discrete case.
</p>
<hr>

<h2><a name="SpecProbGau">Specifying the probabilities</a></h2>
<p>
Now we can specify the probabilities on the network nodes. Default probability distribution is uniform. If we know probability distributions on some of the network nodes, we can specify them with SetPGaussian method for the continuous nodes.
<br>
Let’s set distributions on the nodes x0 and x1.
<p>
<pre>
net.SetPGaussian("x0", "1.0", "4.0")
net.SetPGaussian("x1", "1.0", "1.0")
</pre>
</p>
The first argument of this function is the name of the node. The second is the mean of the corresponding variate, the third – dispersion.
<br>The rest nodes have parents. To set probability distributions on this node we have to call the following functions:
<p>
<pre>
net.SetPGaussian("x2", "0.0", "2.0", "1.0 2.0");
net.SetPGaussian("x3", "0.0", "4.0", "1.1");
net.SetPGaussian("x4", "-0.8", "1.2", "2.0");
</pre>
</p>
The last parameter defines weights. We must specify weight for every parent of the current node.
We can get the parameters of continuous distribution, that we have already specified, with the help of the following methods:
<p>
<pre>
TokArr MeanX0 = net.GetGaussianMean("x0"); 
</pre>
</p>
This method will return the mean of the variate, which corresponds the x0 node.
<p>
<pre>
TokArr CovarX0 = net.GetGaussianCovar("x0");
</pre>
</p>
This method will return the dispersion of the variate, which corresponds the x0 node.
<p>We can carry out Learning, i.e. to find out distributions on the network nodes with the help of one observation or some set of observations. We have to specify observations first.
</p>
<hr>


<h2><a name="AddObservGau">Adding observations</a></h2>
<p>
Here we will describe the way of working with evidences in wrappers. BayesNet class allows user to work with current evidence and with the buffer of  evidences.
<br>Default current evidence is empty. User can edit it with the EditEvidence method:
<p>
<pre>
net.editEvidence("x0^dim1^0.4");
</pre>
</p>
While defining the observation on the continuous node, it is necessary to specify the name of the node, the name of the dimension and the observed value. 
<br>You can also put evidence to evidence buffer without editing. Call AddEvidToBuf method:
<p>
<pre>
net.AddEvidToBuf("x0^dim1^0.4");
</pre>
</p>
Usage of the other functions, which are calling to work with evidences (CurEvidToBuf, ClearEvid, ClearEvidBuf, SaveEvidBuffer, LoadEvidBuffer, GenerateEvidences), is similar to the discrete case.
<hr>


<h2><a name="LearnGau">Learning the network</a></h2>
<p>
Learning of continuous network is similar to learning the discrete one. To carry out learning process use the following calls: 
<p> 
<pre>
net.LearnParameters();
net.LearnStructure();
</pre>
</p>
To get the result distributions after learning user have to use GetGaussianMean and GetGaussianCovar methods:
<p>
<pre>
TokArr MeanX2 = net.GetGaussianMean("x2");
TokArr CovarX2 = net.GetGaussianCovar("x2");
</pre>
</p>
<hr>

<h2><a name="MPEandJPDGau">Getting MPE and JPD</a></h2>
<p>
If Bayesian network and probability distributions have been already defined, we can get Joint Probability Distribution (JPD) and Maximum Probability Explanation (MPE). 
<br>This possibility is well described for the discrete networks. For the continuous networks it is the same.
<p>
<pre>
TokArr X3Marg = net.GetJPD("x3");
TokArr X3MPE = net.GetMPE("x3");
</pre>
</p>
<hr>

